{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data=pd.read_csv(\"Train_UWu5bXk.csv\")\n",
    "Test_data=pd.read_csv(\"Test_u94Q5KV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=Train_data.append(Test_data,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Item_Fat_Content'] = Data['Item_Fat_Content'].replace({'LF':'Low Fat','reg':'Regular','low fat':'Low Fat'})\n",
    "Data.groupby('Item_Identifier')['Item_Weight'].mean().head(5)\n",
    "for i in Data.groupby('Item_Identifier')['Item_Weight'].mean().index:\n",
    "    Data.loc[Data.loc[:,'Item_Identifier']==i,'Item_Weight']=Data.groupby('Item_Identifier')['Item_Weight'].mean()[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Supermarket Type1    9294\n",
       "Grocery Store        1805\n",
       "Supermarket Type3    1559\n",
       "Supermarket Type2    1546\n",
       "Name: Outlet_Type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['Outlet_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small    880\n",
      "Name: Outlet_Size, dtype: int64\n",
      "Small     3100\n",
      "High      1553\n",
      "Medium    1550\n",
      "Name: Outlet_Size, dtype: int64\n",
      "Medium    1546\n",
      "Name: Outlet_Size, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Data.Outlet_Size[Data['Outlet_Type']=='Grocery Store'].value_counts())\n",
    "print(Data.Outlet_Size[Data['Outlet_Type']=='Supermarket Type1'].value_counts())\n",
    "print(Data.Outlet_Size[Data['Outlet_Type']=='Supermarket Type2'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data['Outlet_Size'].fillna(Data['Outlet_Size'].mode()[0],inplace=True)\n",
    "Data.Outlet_Size.fillna(Data.Outlet_Size[Data['Outlet_Type']=='Grocery Store'].mode()[0],inplace=True)\n",
    "Data.Outlet_Size.fillna(Data.Outlet_Size[Data['Outlet_Type']=='Supermarket Type1'].mode()[0],inplace=True)\n",
    "Data.Outlet_Size.fillna(Data.Outlet_Size[Data['Outlet_Type']=='Supermarket Type2'].mode()[0],inplace=True)\n",
    "Data.Outlet_Size.fillna(Data.Outlet_Size[Data['Outlet_Type']=='Supermarket Type3'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Data.groupby('Item_Identifier')['Item_Visibility'].mean().index:\n",
    "    Data.loc[Data.loc[:,'Item_Identifier']==i,'Item_Visibility']=Data.groupby('Item_Identifier')['Item_Visibility'].mean()[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Outlet_Establishment_Year']=2013-Data['Outlet_Establishment_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                     0\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                     0\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales            5681\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data=Data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghost/anaconda3/envs/env2/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "Test_Data=Data[Data['Item_Outlet_Sales'].isnull()]\n",
    "Test_Data.drop('Item_Outlet_Sales',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list=['Item_Fat_Content','Item_Type','Outlet_Identifier','Outlet_Size','Outlet_Location_Type','Outlet_Type','Outlet_Establishment_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghost/anaconda3/envs/env2/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ghost/anaconda3/envs/env2/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/ghost/anaconda3/envs/env2/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/ghost/anaconda3/envs/env2/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "for i in categorical_list:\n",
    "    Train_data[i]=le.fit_transform(Train_data[i])\n",
    "    Train_data[i]=Train_data[i].astype('category')\n",
    "    Test_Data[i]=le.fit_transform(Test_Data[i])\n",
    "    Test_Data[i]=Test_Data[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Data\n",
      "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility Item_Type  \\\n",
      "0           FDA15         9.30                0         0.017235         4   \n",
      "1           DRC01         5.92                1         0.020653        14   \n",
      "2           FDN15        17.50                0         0.017457        10   \n",
      "3           FDX07        19.20                1         0.017834         6   \n",
      "4           NCD19         8.93                0         0.009780         9   \n",
      "\n",
      "   Item_MRP Outlet_Identifier Outlet_Establishment_Year Outlet_Size  \\\n",
      "0  249.8092                 9                         4           1   \n",
      "1   48.2692                 3                         0           1   \n",
      "2  141.6180                 9                         4           1   \n",
      "3  182.0950                 0                         5           2   \n",
      "4   53.8614                 1                         7           0   \n",
      "\n",
      "  Outlet_Location_Type Outlet_Type  Item_Outlet_Sales  \n",
      "0                    0           1          3735.1380  \n",
      "1                    2           2           443.4228  \n",
      "2                    0           1          2097.2700  \n",
      "3                    2           0           732.3800  \n",
      "4                    2           1           994.7052  \n",
      "Test Data\n",
      "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility Item_Type  \\\n",
      "0           FDW58       20.750                0         0.007350        13   \n",
      "1           FDW14        8.300                1         0.033997         4   \n",
      "2           NCN55       14.600                0         0.057385        11   \n",
      "3           FDQ58        7.315                0         0.011914        13   \n",
      "4           FDY38       13.600                1         0.129218         4   \n",
      "\n",
      "   Item_MRP Outlet_Identifier Outlet_Establishment_Year Outlet_Size  \\\n",
      "0  107.8622                 9                         4           1   \n",
      "1   87.3198                 2                         1           2   \n",
      "2  241.7538                 0                         5           2   \n",
      "3  155.0340                 2                         1           2   \n",
      "4  234.2300                 5                         8           1   \n",
      "\n",
      "  Outlet_Location_Type Outlet_Type  \n",
      "0                    0           1  \n",
      "1                    1           1  \n",
      "2                    2           0  \n",
      "3                    1           1  \n",
      "4                    2           3  \n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data\")\n",
    "print(Train_data.head())\n",
    "print(\"Test Data\")\n",
    "print(Test_Data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=9, kernel_initializer='Orthogonal', activation='elu'))  \n",
    "    model.add(Dense(10,activation='elu',kernel_initializer='Orthogonal'))  \n",
    "    model.add(Dense(1, kernel_initializer='Orthogonal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=12, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f67d87f0860>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(Train_data.drop(['Item_Outlet_Sales','Outlet_Identifier','Item_Identifier'],axis=1),Train_data['Item_Outlet_Sales'], batch_size = 12, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=Train_data.drop(['Item_Outlet_Sales'],axis=1)\n",
    "predictions=Train_data['Item_Outlet_Sales']\n",
    "out=[]\n",
    "for i in range(len(Test_Data)):\n",
    "    estimator.fit(Train_data.drop(['Item_Outlet_Sales','Outlet_Identifier','Item_Identifier'],axis=1),Train_data['Item_Outlet_Sales'], batch_size = 12, epochs = 50)\n",
    "    Output=estimator.predict(Test_Data.drop(['Item_Identifier','Outlet_Identifier'],axis=1)[Test_Data.index==i])\n",
    "    out.append(Output)\n",
    "    train.append(Test_Data[Test_Data.index==i])\n",
    "    predictions.append(pd.Series(Output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
